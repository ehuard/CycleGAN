{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4945,"status":"ok","timestamp":1681354814813,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"IWlgr9hs9vWN"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","import numpy as np\n","from collections import Counter, defaultdict\n","import wandb\n","import tqdm\n","from torchvision.utils import save_image"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1681354814813,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"tPgS2blr-zoi","outputId":"ce447aa2-3f0b-45e7-abfb-c1798dd02909"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1681354833820,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"EFBbEc3hP_1K"},"outputs":[],"source":["def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    checkpoint = {\n","        \"state_dict\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, filename)\n","\n","\n","def load_checkpoint(checkpoint_file, model, optimizer, lr):\n","    print(\"=> Loading checkpoint\")\n","    checkpoint = torch.load(checkpoint_file, map_location=config['device'])\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","\n","    # If we don't do this then it will just have learning rate of old checkpoint\n","    # and it will lead to many hours of debugging \\:\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n"]},{"cell_type":"markdown","metadata":{"id":"BkXFQk8cOplB"},"source":["# Définition du modèle"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1681354833821,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"WAN6afB6-0zr"},"outputs":[],"source":["class Block(nn.Module):\n","  def __init__(self, nb_in_layers, nb_out_layers, stride):\n","    super().__init__()\n","    self.conv = nn.Sequential(\n","        nn.Conv2d(nb_in_layers, nb_out_layers, 4, stride, padding=1, bias=True, padding_mode=\"reflect\"),\n","        nn.InstanceNorm2d(nb_out_layers),\n","        nn.LeakyReLU(0.2),\n","    )\n","\n","  def forward(self, x):\n","    return self.conv(x)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1681354833822,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"2MAW0IOI_5Er"},"outputs":[],"source":["class Discriminator(nn.Module):\n","  def __init__(self, nb_in_layers=3, features=[64, 128, 256, 512]):\n","    super().__init__()\n","    self.initial = nn.Sequential(\n","        nn.Conv2d(nb_in_layers, features[0], kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\",),\n","        nn.LeakyReLU(0.2),\n","        )\n","    self.layers = nn.ModuleList()\n","    in_channels = features[0]\n","    for idx, feature in enumerate(features[1:]):\n","      if feature == features[-1]:\n","        self.layers.add_module(f'Block{idx}_{feature}', Block(in_channels, feature, stride=1))\n","      else:\n","        self.layers.add_module(f'Block{idx}_{feature}', Block(in_channels, feature, stride=2))\n","      in_channels = feature\n","    self.layers.add_module('OutputMapping', nn.Conv2d(in_channels, out_channels=1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"))\n","\n","  def forward(self, x):\n","    x = self.initial(x)\n","    for layer in self.layers:\n","      x = layer(x)\n","    return torch.sigmoid(x)    "]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":660,"status":"ok","timestamp":1681354834473,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"8N68trIP_4qm","outputId":"a328354b-5307-4ee7-fb68-5b623bfec042"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 1, 30, 30])\n"]}],"source":["# test\n","x = torch.randn((5,3,256,256)) # 5 images, en RGB, de taille 256 256\n","model = Discriminator()\n","preds = model(x)\n","print(preds.shape) # on s'attend à 5 images, 1 seul canal, taille 30 par 30"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1681354834474,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"T3bbYuYOE7Nt"},"outputs":[],"source":["class ConvBlock(nn.Module):\n","  def __init__(self, nb_in_layers, nb_out_layers, down=True, use_act=True, **kwargs):\n","    super().__init__()\n","    self.conv = nn.Sequential(\n","        nn.Conv2d(nb_in_layers, nb_out_layers, padding_mode=\"reflect\", **kwargs) if down\n","        else nn.ConvTranspose2d(nb_in_layers, nb_out_layers, **kwargs),\n","        nn.ReLU(inplace=True) if use_act else nn.Identity()\n","    )\n","\n","  def forward(self, x):\n","    return self.conv(x)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1681354834474,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"q5aAs268GR_a"},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","  def __init__(self, channels):\n","    super().__init__()\n","    self.block = nn.Sequential(\n","        ConvBlock(channels, channels, kernel_size=3, padding=1),\n","        ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1)\n","    )\n","  \n","  def forward(self, x):\n","    return x + self.block(x)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1681354834475,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"tKomsKvMGRbz"},"outputs":[],"source":["class Generator(nn.Module):\n","  def __init__(self, img_channels, num_residuals=9):\n","    super().__init__()\n","    self.initial = nn.Sequential(\n","        nn.Conv2d(img_channels, 64, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.down_path = nn.ModuleList([\n","        ConvBlock(64, 128, kernel_size=3, down=True, stride=2, padding=1),\n","        ConvBlock(128, 256, kernel_size=3, down=True, stride=2, padding=1),\n","    ])\n","    self.residual_blocks = nn.Sequential(\n","       *[ResidualBlock(256) for _ in range(num_residuals)] \n","    )\n","    self.up_path = nn.ModuleList([\n","        ConvBlock(256, 128, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n","        ConvBlock(128, 64, down=False, kernel_size=3, stride=2, padding=1, output_padding=1)\n","    ])\n","    self.colorize = nn.Conv2d(64, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n","  \n","  def forward(self, x):\n","    x = self.initial(x)\n","    for layer in self.down_path:\n","      x = layer(x)\n","    x = self.residual_blocks(x)\n","    for layer in self.up_path:\n","      x = layer(x)\n","    return torch.tanh(self.colorize(x))"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["class UnetGenerator(nn.Module):\n","  def __init__(self, img_channels, num_residuals=9):\n","    super().__init__()\n","    self.initial = nn.Sequential(\n","        nn.Conv2d(img_channels, 64, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.down_path = nn.ModuleList([\n","        ConvBlock(64, 128, kernel_size=3, down=True, stride=2, padding=1),\n","        ConvBlock(128, 256, kernel_size=3, down=True, stride=2, padding=1),\n","    ])\n","    self.residual_blocks = nn.Sequential(\n","       *[ResidualBlock(256) for _ in range(num_residuals)] \n","    )\n","    self.up_path = nn.ModuleList([\n","        ConvBlock(256, 128, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n","        ConvBlock(128*2, 64, down=False, kernel_size=3, stride=2, padding=1, output_padding=1)\n","    ])\n","    self.colorize = nn.Conv2d(64*2, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n","  \n","  def forward(self, x):\n","    x = self.initial(x)\n","    skip_connections = []\n","    skip_connections.append(x)\n","    for layer in self.down_path:\n","      #print(\"down size\", x.shape)\n","      x = layer(x)\n","      skip_connections.append(x)\n","    #concat_input = torch.concat([skip_connections[-1], x], 1)\n","    x = self.residual_blocks(x)\n","    for idx in range(len(self.up_path)):\n","      #print(\"x in shape\",x.shape)\n","      x = self.up_path[idx](x)\n","      #print(\"x output shape\",x.shape)\n","      #print(\"sc shape \", skip_connections[-(idx+1)-1].shape)\n","      x= torch.concat((skip_connections[-(idx+1)-1],x),1)\n","    return torch.tanh(self.colorize(x))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9811,"status":"ok","timestamp":1681354844280,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"EbuXC-87N8tc","outputId":"ddaf3949-95fe-4dc7-f475-d54f7838a5e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 3, 256, 256])\n"]}],"source":["# test\n","x = torch.randn((5,3,256,256)) # 5 images, en RGB, de taille 256 256\n","model = Generator(img_channels=3)\n","preds = model(x)\n","print(preds.shape) # on s'attend à 5 images, 3 canaux, taille 256 par 256"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 3, 256, 256])\n"]}],"source":["# test\n","x = torch.randn((5,3,256,256)) # 5 images, en RGB, de taille 256 256\n","model = UnetGenerator(img_channels=3)\n","preds = model(x)\n","print(preds.shape) # on s'attend à 5 images, 3 canaux, taille 256 par 256"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Advanced U-Net Generator "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class DoubleConvBlock(nn.Module):\n","    def __init__(self, nb_in_layers, nb_out_layers):\n","        super(DoubleConvBlock, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(nb_in_layers, nb_out_layers, 3, 1, 1, padding_mode=\"reflect\", bias=False),\n","            nn.InstanceNorm2d(nb_out_layers),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(nb_out_layers, nb_out_layers, 3, 1, 1, padding_mode=\"reflect\", bias=False),\n","            nn.InstanceNorm2d(nb_out_layers),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["class UnetGeneratorAdvanced(nn.Module):\n","    def __init__(\n","            self, img_channels=3, features=[32, 64, 128], num_residuals=6\n","    ):\n","        super(UnetGeneratorAdvanced, self).__init__()\n","        self.up_path = nn.ModuleList()\n","        self.down_path = nn.ModuleList()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # On augmente le nombre de layers et on diminue la taille des images\n","        in_channels = img_channels\n","        for feature in features:\n","            self.down_path.append(DoubleConvBlock(in_channels, feature))\n","            in_channels = feature\n","\n","        # On augmente la taille des images et on dimini=ue le nombre de layers\n","        for feature in reversed(features):\n","            self.up_path.append(\n","                nn.ConvTranspose2d( # pour faire le upsampling\n","                    feature*2, feature, kernel_size=2, stride=2,\n","                )\n","            )\n","            self.up_path.append(DoubleConvBlock(feature*2, feature))\n","\n","        #self.bottleneck = DoubleConvBlock(features[-1], features[-1]*2)\n","        self.bottleneck = nn.Sequential(\n","            DoubleConvBlock(features[-1], features[-1]*2),\n","            *[ResidualBlock(features[-1]*2) for _ in range(num_residuals-1)] )\n","        self.colorize = nn.Conv2d(features[0], img_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        skip_connections = []\n","\n","        for down in self.down_path:\n","            x = down(x)\n","            skip_connections.append(x)\n","            x = self.pool(x)\n","        x = self.bottleneck(x)\n","        skip_connections = skip_connections[::-1]\n","        for idx in range(0, len(self.up_path), 2):\n","            x = self.up_path[idx](x)\n","            skip_connection = skip_connections[idx//2]\n","\n","            #if x.shape != skip_connection.shape:\n","            #    x = TF.resize(x, size=skip_connection.shape[2:])\n","\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            x = self.up_path[idx+1](concat_skip)\n","\n","        return self.colorize(x)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 3, 256, 256])\n"]}],"source":["# test\n","x = torch.randn((5,3,256,256)) # 5 images, en RGB, de taille 256 256\n","model = UnetGeneratorAdvanced(img_channels=3)\n","preds = model(x)\n","print(preds.shape) # on s'attend à 5 images, 3 canaux, taille 256 par 256"]},{"cell_type":"markdown","metadata":{"id":"MRoBxy-LUcbI"},"source":["# Training Loop"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":164,"status":"ok","timestamp":1681354844657,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"msYA5P4LUhSa"},"outputs":[],"source":["def train_epoch(disc_A, disc_B, gen_A, gen_B, loader, opt_disc, opt_gen, config, d_scaler, g_scaler, num_epoch):\n","  \"\"\"\n","  Entraînement sur 1 epoch\n","  \"\"\"\n","  loop = tqdm.tqdm(loader, leave=True)\n","  logs = defaultdict(list)\n","  device = config['device']\n","  A_name = config['A_name']\n","  B_name = config['B_name']\n","  cycle_loss_fun = config['cycle_loss'] # à changer plus tard, c'est à dire qu'il faut renplacer mse et L1 dans le code ci dessous\n","  adversarial_loss_fun = config['adversarial_loss']\n","  if config['identity_lambda']>0:\n","    identity_loss_fun = config['identity_loss'].to(device)\n","  for idx, (img_A, img_B) in enumerate(loop):\n","    metrics = dict()\n","    img_A = img_A.to(config[\"device\"])\n","    img_B = img_B.to(config[\"device\"])\n","\n","    # Train discriminators\n","    with torch.cuda.amp.autocast():\n","      # loss du discriminateur vraie/fausse img_B\n","      #print(\"img_A shape\", img_A.shape)\n","      fake_img_B = gen_B(img_A)\n","      D_B_real = disc_B(img_B) \n","      D_B_fake = disc_B(fake_img_B.detach())\n","      D_B_real_loss = adversarial_loss_fun(D_B_real, torch.ones_like(D_B_real))\n","      D_B_fake_loss = adversarial_loss_fun(D_B_fake, torch.zeros_like(D_B_fake))\n","      D_B_loss = D_B_real_loss + D_B_fake_loss\n","      # loss du discriminateur vrai/faux img_A\n","      fake_img_A = gen_A(img_B)\n","      D_A_real = disc_A(img_A)\n","      D_A_fake = disc_A(fake_img_A.detach())\n","      D_A_real_loss = adversarial_loss_fun(D_A_real, torch.ones_like(D_A_real))\n","      D_A_fake_loss = adversarial_loss_fun(D_A_fake, torch.zeros_like(D_A_fake))\n","      D_A_loss = D_A_real_loss + D_A_fake_loss\n","      # rassemble les 2 \n","      D_loss = (D_A_loss + D_B_loss)/2 # important de diviser par 2? jsp\n","    opt_disc.zero_grad() # remet le gradient à 0\n","    d_scaler.scale(D_loss).backward()\n","    d_scaler.step(opt_disc)\n","    d_scaler.update()\n","\n","    # Train Generators\n","    with torch.cuda.amp.autocast():\n","      # adversarial losses\n","      D_A_fake = disc_A(fake_img_A)\n","      D_B_fake = disc_B(fake_img_B)\n","      G_A_loss = adversarial_loss_fun(D_A_fake, torch.ones_like(D_A_fake))\n","      G_B_loss = adversarial_loss_fun(D_B_fake, torch.ones_like(D_B_fake))\n","\n","      # cycle loss\n","      cycle_B = gen_B(fake_img_A)\n","      cycle_A = gen_A(fake_img_B)\n","      cycle_B_loss = cycle_loss_fun(img_B, cycle_B)\n","      cycle_A_loss = cycle_loss_fun(img_A, cycle_A)\n","\n","      # ajouter identity loss\n","      if config['identity_lambda']>0:\n","        #On vérifie que G(y) = y et F(x) = x i.e. que les générateurs soient des fonctions identités\n","        #par rapport à ce qu'ils doivent reproduire. Donc le générateur de Monet doit être l'identité\n","        #si on lui passe en entrée un Monet.\n","        B_identity_loss = identity_loss_fun(gen_B(img_B), img_B)\n","        A_identity_loss = identity_loss_fun(gen_A(img_A), img_A)\n","        identity_loss = B_identity_loss + A_identity_loss\n","      else : identity_loss = 0\n","\n","      # rassemble tout\n","      G_loss = (G_A_loss + G_B_loss + \n","                (cycle_B_loss + cycle_A_loss)*config[\"cycle_lambda\"] +\n","                identity_loss * config[\"identity_lambda\"]\n","                )\n","    opt_gen.zero_grad()\n","    g_scaler.scale(G_loss).backward()\n","    g_scaler.step(opt_gen)\n","    g_scaler.update()\n","    \n","\n","    metrics['D_B_real_loss'] = D_B_real_loss.item()\n","    metrics['D_B_fake_loss'] = D_B_fake_loss.item()\n","    metrics['D_B_loss'] = D_B_loss.item()\n","    metrics['D_A_real_loss'] = D_A_real_loss.item()\n","    metrics['D_A_fake_loss'] = D_A_fake_loss.item()\n","    metrics['D_A_loss'] = D_A_loss.item()\n","    metrics['D_loss'] = D_loss.item()\n","    metrics['G_A_loss'] = G_A_loss.item()\n","    metrics['G_B_loss'] = G_B_loss.item()\n","    metrics['cycle_B_loss'] = cycle_B_loss.item()\n","    metrics['cycle_A_loss'] = cycle_A_loss.item()\n","    metrics['G_loss'] = G_loss.item()\n","\n","    for name, value in metrics.items():\n","      logs[name].append(value)\n","\n","    if idx % config['log_every'] == 0:\n","      for name, value in logs.items():\n","          logs[name] = np.mean(value)\n","      train_logs = {\n","          f'Train - {m}': v\n","          for m, v in logs.items() }\n","      wandb.log(train_logs)\n","      logs = defaultdict(list)\n","    \n","\n","    if idx % config['show_image_every'] == 0:\n","      save_image(0.5*fake_img_A+0.5, f\"saved_images/{A_name}_epoch_{num_epoch}_indx_{idx}.png\")\n","      save_image(0.5*fake_img_B+0.5, f\"saved_images/{B_name}_epoch_{num_epoch}_indx_{idx}.png\")\n","\n","  # a la fin de l'epoch, enregistrer des images choisies     \n","  for selected_img_A, selected_img_B, sel_img_A_path, sel_img_B_path in zip(config[\"selected_img_A\"], config[\"selected_img_B\"], selected_img_A_path, selected_img_B_path):\n","    #print(\"selected_img_A shape\", selected_img_A.shape)\n","    save_image(0.5*gen_B(selected_img_A)+0.5, f\"selected_images_end_epoch/{config['model_name']}_{B_name}_{sel_img_A_path[18:-4]}_epoch_{num_epoch}.png\")\n","    save_image(0.5*gen_A(selected_img_B)+0.5, f\"selected_images_end_epoch/{config['model_name']}_{A_name}_{sel_img_B_path[18:-4]}_epoch_{num_epoch}.png\")\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":377,"status":"ok","timestamp":1681354853523,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"oT1sEz3cEHvy"},"outputs":[],"source":["\n","\n","def eval_metrics(disc_A, disc_B, gen_A, gen_B, img_A, img_B, config):\n","    \"\"\"\n","    Calcul des différentes loss. On va utiliser ça que en validation parce qu'on va calculer toutes les loss ici, et ne pas faire de backward\n","    Or, on fait un premier backward sur les discriminateurs avant de calculer les loss des générateurs\n","    Je suis pas sur qu'on ait besoin de faire comme ça, mais bon j'ai vu cette implémentation\n","    Je pense qu'en vrai on pourrait l'utiliser pour le train aussi\n","    Ajouter une métrique d'accuracy sur les deux discriminateurs? mais ils discriminent par patch: vote moyen? vote majoritaire?\n","    \"\"\"\n","    device = config['device']\n","    adversarial_loss = config['adversarial_loss'].to(device)\n","    cycle_loss = config['cycle_loss'].to(device)\n","    if config['identity_lambda']>0:\n","      identity_loss = config['identity_loss'].to(device)\n","    metrics = dict()\n","\n","    with torch.cuda.amp.autocast():\n","      # on genere un objet de la classe B a partir d'un objet de A, et un objet de A à partir d'un objet de B\n","      fake_B = gen_B(img_A)\n","      D_B_real = disc_B(img_B) \n","      D_B_fake = disc_B(fake_B.detach())\n","      # loss du discriminateur vrai/faux objet B\n","      D_B_real_loss = adversarial_loss(D_B_real, torch.ones_like(D_B_real))\n","      D_B_fake_loss = adversarial_loss(D_B_fake, torch.zeros_like(D_B_fake))\n","      D_B_loss = D_B_real_loss + D_B_fake_loss\n","      # loss du discriminateur vrai/faux objet A\n","      fake_A = gen_A(img_B)\n","      D_A_real = disc_A(img_A)\n","      D_A_fake = disc_A(fake_A.detach())\n","      D_A_real_loss = adversarial_loss(D_A_real, torch.ones_like(D_A_real))\n","      D_A_fake_loss = adversarial_loss(D_A_fake, torch.zeros_like(D_A_fake))\n","      D_A_loss = D_A_real_loss + D_A_fake_loss\n","      # rassemble les 2 \n","      D_loss = (D_A_loss + D_B_loss)/2 # important de diviser par 2? jsp\n","\n","    with torch.cuda.amp.autocast():\n","      # adversarial losses\n","      D_A_fake = disc_A(fake_A)\n","      D_B_fake = disc_B(fake_B)\n","      G_A_loss = adversarial_loss(D_A_fake, torch.ones_like(D_A_fake))\n","      G_B_loss = adversarial_loss(D_B_fake, torch.ones_like(D_B_fake))\n","\n","      # cycle loss\n","      cycle_B = gen_B(fake_A)\n","      cycle_A = gen_A(fake_B)\n","      cycle_B_loss = cycle_loss(img_B, cycle_B)\n","      cycle_A_loss = cycle_loss(img_A, cycle_A)\n","\n","      # ajouter identity loss\n","      if config['identity_lambda']>0:\n","        #On vérifie que G(y) = y et F(x) = x i.e. que les générateurs soient des fonctions identités\n","        #par rapport à ce qu'ils doivent reproduire. Donc le générateur de Monet doit être l'identité\n","        #si on lui passe en entrée un Monet.\n","        B_identity_loss = identity_loss(gen_B(img_B), img_B)\n","        A_identity_loss = identity_loss(gen_A(img_A), img_A)\n","        total_identity_loss = B_identity_loss + A_identity_loss\n","      else : total_identity_loss = 0\n","\n","      # rassemble tout\n","      G_loss = (G_A_loss + G_B_loss + \n","                (cycle_B_loss + cycle_A_loss)*config[\"cycle_lambda\"] +\n","                total_identity_loss * config[\"identity_lambda\"]\n","                )\n","      \n","    metrics['D_B_real_loss'] = D_B_real_loss.item()\n","    metrics['D_B_fake_loss'] = D_B_fake_loss.item()\n","    metrics['D_B_loss'] = D_B_loss.item()\n","    metrics['D_A_real_loss'] = D_A_real_loss.item()\n","    metrics['D_A_fake_loss'] = D_A_fake_loss.item()\n","    metrics['D_A_loss'] = D_A_loss.item()\n","    metrics['D_loss'] = D_loss.item()\n","    metrics['G_A_loss'] = G_A_loss.item()\n","    metrics['G_B_loss'] = G_B_loss.item()\n","    metrics['cycle_B_loss'] = cycle_B_loss.item()\n","    metrics['cycle_A_loss'] = cycle_A_loss.item()\n","    metrics['G_loss'] = G_loss.item()\n","    \n","    return metrics\n","\n","\n","\n","def eval(disc_A, disc_B, gen_A, gen_B, dataloader, config):\n","  device = config['device']\n","  disc_A.to(device)\n","  disc_B.to(device)\n","  gen_A.to(device)\n","  gen_B.to(device)\n","  disc_A.eval()\n","  disc_B.eval()\n","  gen_A.eval()\n","  gen_B.eval()\n","  logs = defaultdict(list)\n","  with torch.no_grad():\n","    for img_A, img_B in dataloader:\n","      img_A = img_A.to(device)\n","      img_B = img_B.to(device)\n","      metrics = eval_metrics(disc_A, disc_B, gen_A, gen_B, img_A, img_B, config)\n","    for name, value in metrics.items():\n","        logs[name].append(value)\n","  return logs"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1681354853524,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"nCMPd5JWD93T"},"outputs":[],"source":["def train(disc_A, disc_B, gen_A, gen_B, train_loader, val_loader, opt_disc, opt_gen, config, d_scaler, g_scaler):\n","  \n","  for n in range(config['epochs']):\n","    # peut etre changer le learning rate\n","    if n==55:\n","      config['lr'] = config['lr']/4\n","      opt_disc.lr = config['lr']\n","      opt_gen.lr = config['lr']/2\n","    if n==80:\n","      config['lr'] = config['lr']/2\n","      opt_disc.lr = config['lr']\n","      opt_gen.lr = config['lr']/2\n","    train_epoch(disc_A, disc_B, gen_A, gen_B, train_loader, opt_disc, opt_gen, config, d_scaler, g_scaler, n)\n","\n","    logs = eval(disc_A, disc_B, gen_A, gen_B, val_loader, config)\n","    for name, value in logs.items():\n","        logs[name] = np.mean(value)\n","    val_logs = {\n","        f'Validation - {m}': v\n","        for m, v in logs.items()\n","    }\n","    print(\"val logs:\",val_logs)\n","    wandb.log(val_logs)\n","    save_checkpoint(gen_A, opt_gen, filename=\"saved_model/gen_A.pth.tar\")\n","    save_checkpoint(gen_B, opt_gen, filename=\"saved_model/gen_B.pth.tar\")\n","    save_checkpoint(disc_A, opt_disc, filename=\"saved_model/disc_A.pth.tar\")\n","    save_checkpoint(disc_B, opt_disc, filename=\"saved_model/disc_B.pth.tar\")\n"]},{"cell_type":"markdown","metadata":{"id":"4p8D-apIO_1d"},"source":["# Config"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":181,"status":"ok","timestamp":1681354853702,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"OVwddUznPBit"},"outputs":[],"source":["\n","# model_name_numeroepoch_numeroidx.jpg\n","\n","\n","config = {\n","    'model_name' : \"Classic\",\n","    'A_name' : 'horse',\n","    'B_name' : 'zebra',\n","    'epochs': 120,\n","    'log_every': 350,\n","    'show_image_every':500,\n","    'batch_size': 1,\n","    'lr': 2e-4,\n","    'betas': (0.9, 0.999),\n","    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n","    'cycle_lambda' : 10,\n","    'identity_lambda' : 0,\n","    'adversarial_loss' : nn.MSELoss(),\n","    'cycle_loss' : nn.L1Loss(),\n","    'identity_loss' : nn.L1Loss(),\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"tjEtJowVOmEZ"},"source":["# Chargement des données"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":1914,"status":"ok","timestamp":1681354855613,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"JIZYDgSyOofZ"},"outputs":[],"source":["from PIL import Image\n","from torchvision import transforms\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":306,"status":"ok","timestamp":1681354855917,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"SVbScQ6f2IcA"},"outputs":[],"source":["transforms = A.Compose(\n","    [\n","        A.Resize(width=256, height=256),\n","        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n","        ToTensorV2(),\n","    ]\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1681354855918,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"knGgrewnOvdV"},"outputs":[],"source":["class Custom_AB_Dataset(Dataset):\n","  def __init__(self, root_A, root_B):\n","    self.root_A = root_A\n","    self.root_B = root_B\n","    \n","    self.A_images = os.listdir(root_A)\n","    self.B_images = os.listdir(root_B)\n","    self.A_length = len(self.A_images)\n","    self.B_length = len(self.B_images)\n","    self.length_dataset = max(self.A_length, self.B_length)\n","    #self.length_dataset = 50 # mettre à genre 50 ou 200 pour vérifier rapidement que le code tourne sur plusieurs epochs\n","\n","  def __len__(self):\n","    return self.length_dataset\n","\n","  def __getitem__(self, index):\n","    A_img = self.A_images[index%self.A_length] # certains exemples (indices plus faibles) risquent d'être montrés une fois de plus à chaque epoch que les autres\n","    B_img = self.B_images[index%self.B_length]\n","\n","    A_path = os.path.join(self.root_A, A_img)\n","    B_path = os.path.join(self.root_B, B_img)\n","\n","\n","    A_img = np.array(Image.open(A_path).convert(\"RGB\"))\n","    B_img = np.array(Image.open(B_path).convert(\"RGB\"))\n","\n","    A_img = transforms(image=A_img)[\"image\"]\n","    B_img = transforms(image=B_img)[\"image\"]\n","    return A_img, B_img"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["#Construction de la liste qui va contenir les images selectionnees\n","selected_horse_path = [\"horse2zebra/testA/n02381460_1110.jpg\", \n"," \"horse2zebra/testA/n02381460_1820.jpg\",\n"," \"horse2zebra/testA/n02381460_4550.jpg\",\n"," \"horse2zebra/testA/n02381460_7170.jpg\",\n"," \"horse2zebra/testA/n02381460_7400.jpg\"]\n","selected_zebra_path = [\"horse2zebra/testB/n02391049_490.jpg\",\n","                   \"horse2zebra/testB/n02391049_1430.jpg\",\n","                   \"horse2zebra/testB/n02391049_1220.jpg\",\n","                   \"horse2zebra/testB/n02391049_6780.jpg\",\n","                   \"horse2zebra/testB/n02391049_10100.jpg\"]\n","selected_horse, selected_zebra = [], []\n","\n","for sel_horse_path, sel_zebra_path in zip(selected_horse_path, selected_zebra_path):\n","      sel_horse = Image.open(sel_horse_path).convert(\"RGB\")\n","      sel_zebra = Image.open(sel_zebra_path).convert(\"RGB\")\n","\n","      sel_horse = np.array(sel_horse)\n","      sel_zebra = np.array(sel_zebra)\n","\n","      augmentations = transforms(image = sel_horse, image0 = sel_zebra)\n","\n","      selected_horse.append(transforms(image=sel_horse)[\"image\"].to(device)[None,:])\n","      selected_zebra.append(transforms(image=sel_zebra)[\"image\"].to(device)[None,:])\n","\n","\n","selected_img_A_path = selected_horse_path\n","selected_img_B_path = selected_zebra_path\n","config['selected_img_A'] = selected_horse\n","config['selected_img_B'] = selected_zebra"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1681354872012,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"-gg1oz-LdbUZ","outputId":"987da890-23c2-44aa-e569-db8bd37f7507"},"outputs":[{"name":"stderr","output_type":"stream","text":["'ls' n'est pas reconnu en tant que commande interne\n","ou externe, un programme ex�cutable ou un fichier de commandes.\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":32725,"status":"ok","timestamp":1681354904735,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"_ihYdngoddwf"},"outputs":[],"source":["train_dataset = Custom_AB_Dataset(\"horse2zebra/trainA\", \"horse2zebra/trainB\")"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1681354904736,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"TWcQHUYkeBG1","outputId":"362ea426-61e9-410f-ccc7-d8af8d55f84a"},"outputs":[{"data":{"text/plain":["1334"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["len(train_dataset)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1681354904736,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"BD9DX-oGeNP1"},"outputs":[],"source":["train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=config[\"batch_size\"],\n","    shuffle=True,\n","    num_workers=0,\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":809,"status":"ok","timestamp":1681354905532,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"eYDuTe0FSNkB","outputId":"dc1a65dc-79e6-4c16-9dc9-43e64f9d2a3f"},"outputs":[{"data":{"text/plain":["48"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["val_dataset = Custom_AB_Dataset(\"horse2zebra/valA\", \"horse2zebra/valB\")\n","len(val_dataset)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1681354905533,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"Cc8NyzdQSNpx"},"outputs":[],"source":["val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=config[\"batch_size\"],\n","    shuffle=True,\n","    num_workers=0,\n",")"]},{"cell_type":"markdown","metadata":{"id":"AI_gxBczbM0K"},"source":["# Training the models"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"YLVwi1YBbOVf"},"outputs":[],"source":["disc_A = Discriminator(nb_in_layers=3).to(config['device']) # vrai Cheval ou génération?\n","disc_B = Discriminator(nb_in_layers=3).to(config['device']) # vrai Zebre ou génération ? \n","gen_A = Generator(img_channels=3, num_residuals=9).to(config['device'])\n","gen_B = Generator(img_channels=3, num_residuals=9).to(config['device'])"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"_FL9Vbdobotn"},"outputs":[],"source":["import torch.optim as optim\n","\n","opt_disc = optim.Adam(\n","    list(disc_A.parameters()) + list(disc_B.parameters()),\n","    lr = config['lr']/2,\n","    betas=config['betas']\n",")\n","opt_gen = optim.Adam(\n","    list(gen_A.parameters()) + list(gen_B.parameters()),\n","    lr=config['lr'],\n","    betas=config['betas']\n",")"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"wSn4cb7Xc4s_"},"outputs":[],"source":["g_scaler = torch.cuda.amp.GradScaler()\n","d_scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4217,"status":"ok","timestamp":1681331164823,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"s30wSKATSYIB","outputId":"cd6f8f4e-92dd-4cfb-eeef-1a2ad39591d1"},"outputs":[{"name":"stderr","output_type":"stream","text":["wandb: Currently logged in as: erichuard-second (pasdutoutlate). Use `wandb login --relogin` to force relogin\n"]},{"name":"stdout","output_type":"stream","text":["Sun Apr 30 00:38:28 2023       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 531.14                 Driver Version: 531.14       CUDA Version: 12.1     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA GeForce RTX 3060 L...  WDDM | 00000000:01:00.0  On |                  N/A |\n","| N/A   37C    P8               15W /  N/A|   1492MiB /  6144MiB |     21%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|    0   N/A  N/A      1284    C+G   ...m\\radeonsoftware\\RadeonSoftware.exe    N/A      |\n","|    0   N/A  N/A      1920    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n","|    0   N/A  N/A      2116    C+G   ...on\\112.0.1722.58\\msedgewebview2.exe    N/A      |\n","|    0   N/A  N/A      2896    C+G   ...6.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n","|    0   N/A  N/A      4604    C+G   ...\\Local\\slack\\app-4.31.155\\slack.exe    N/A      |\n","|    0   N/A  N/A      4620    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n","|    0   N/A  N/A     11412    C+G   C:\\Windows\\explorer.exe                   N/A      |\n","|    0   N/A  N/A     11428    C+G   ...pdnekdrzrea0\\XboxGameBarSpotify.exe    N/A      |\n","|    0   N/A  N/A     14704    C+G   ...7.0_x64__w2gh52qy24etm\\Nahimic3.exe    N/A      |\n","|    0   N/A  N/A     14940    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     15204    C+G   ..._8wekyb3d8bbwe\\PaintApp\\mspaint.exe    N/A      |\n","|    0   N/A  N/A     18684    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n","|    0   N/A  N/A     19724    C+G   ...aam7r\\AcrobatNotificationClient.exe    N/A      |\n","|    0   N/A  N/A     21516    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n","|    0   N/A  N/A     24876    C+G   ...60.0_x86__zpdnekdrzrea0\\Spotify.exe    N/A      |\n","|    0   N/A  N/A     25428    C+G   ..._8wekyb3d8bbwe\\PaintApp\\mspaint.exe    N/A      |\n","|    0   N/A  N/A     27268    C+G   ..._8wekyb3d8bbwe\\PAD.Console.Host.exe    N/A      |\n","|    0   N/A  N/A     27488    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     27992    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n","|    0   N/A  N/A     29248    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n","|    0   N/A  N/A     33232    C+G   C:\\Program Files\\NordVPN\\NordVPN.exe      N/A      |\n","|    0   N/A  N/A     33408    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     33932      C   ...Programs\\Python\\Python38\\python.exe    N/A      |\n","|    0   N/A  N/A     35680    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n","|    0   N/A  N/A     35884    C+G   ...nr4m\\radeonsoftware\\AMDRSSrcExt.exe    N/A      |\n","|    0   N/A  N/A     36936    C+G   ...al\\Discord\\app-1.0.9012\\Discord.exe    N/A      |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["# Checking GPU and logging to wandb\n","\n","!wandb login\n","\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["279e6e2d736b4104a7755f489922625d","5913936c19ad4f83b29662e0da3a858c","7c74c56689bd41e4a18a49747e8e6766","6bb274a1efd44cbfbcf77bbfc9a8417c","9b03ec0a803f4f8195cc8e77e07340e0","3437885a88464b16b163ea49f0cfda87","65d828f4b50740f2aeb6aff11647674b","47ce4f7b031e442e8d4281d4fce33f05"]},"executionInfo":{"elapsed":1315866,"status":"ok","timestamp":1681332480684,"user":{"displayName":"Maxime Gourceyraud","userId":"04000250239260302388"},"user_tz":240},"id":"Itm2svcoSgH4","outputId":"35e723f2-2e16-4059-c36b-3ae0527bd8c1"},"outputs":[],"source":["!wandb online  # online / offline to activate or deactivate WandB logging\n","\n","with wandb.init(\n","        config=config,\n","        project='NOTRE PROJET',  # Title of your project\n","        group='ZebreCheval',  # In what group of runs do you want this run to be in?\n","        save_code=True,\n","        name=\"Classic\",\n","    ):\n","    train(disc_A, disc_B, gen_A, gen_B, train_loader, val_loader, opt_disc, opt_gen, config, d_scaler, g_scaler)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"279e6e2d736b4104a7755f489922625d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_5913936c19ad4f83b29662e0da3a858c","IPY_MODEL_7c74c56689bd41e4a18a49747e8e6766"],"layout":"IPY_MODEL_6bb274a1efd44cbfbcf77bbfc9a8417c"}},"3437885a88464b16b163ea49f0cfda87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47ce4f7b031e442e8d4281d4fce33f05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5913936c19ad4f83b29662e0da3a858c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b03ec0a803f4f8195cc8e77e07340e0","placeholder":"​","style":"IPY_MODEL_3437885a88464b16b163ea49f0cfda87","value":"0.074 MB of 0.074 MB uploaded (0.000 MB deduped)\r"}},"65d828f4b50740f2aeb6aff11647674b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bb274a1efd44cbfbcf77bbfc9a8417c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c74c56689bd41e4a18a49747e8e6766":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_65d828f4b50740f2aeb6aff11647674b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47ce4f7b031e442e8d4281d4fce33f05","value":1}},"9b03ec0a803f4f8195cc8e77e07340e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
